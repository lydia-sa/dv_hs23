{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Textklassifikation für Deutsche Texte 1\n",
    "Unser Newsdatensatz aus den Aufgaben zur Textähnlichkeit beinhaltet leider keine Kategorien, so dass eine überwachte Klassifikation nicht möglich ist.\n",
    "\n",
    "Daher habe ich einen weiteren Datensatz verfügbar gemacht: 10kGNDA (Zehntausend deutsche Zeitungsartikel).\n",
    "\n",
    "Anhand dieses Datensatzes soll die Textklassifikation auf deutsche Sprache übertragen werden. Passen sie dazu den Code von Sarkar geeignet an. Folgende Einschränkungen vereinfachen die Aufgabe etwas:\n",
    "\n",
    "- Starten sie zunächst mit dem (kleineren) Testdatensatz. Das sollte die Berechnungen etwas schneller ablaufen lassen.\n",
    "- Falls alles funktioniert, können sie zusätzlich noch den Trainingsdatensatz verwenden. Entweder fertig aufgeteilt (training, test) oder zuerst zusammenfassen und dann im Programm aufteilen lassen.\n",
    "- Sie müssen nicht alle Methoden umsetzen, wählen sie zwei aus.\n",
    "- Starten sie zunächst ohne Hyperparameter-Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from Normalisieren_DE import normalize_corpus\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "     Target Name                                            Article\n0     Wirtschaft  'Die Gewerkschaft GPA-djp lanciert den \"All-in...\n1          Sport  Franzosen verteidigen 2:1-Führung – Kritische ...\n2            Web  'Neues Video von Designern macht im Netz die R...\n3          Sport  23-jähriger Brasilianer muss vier Spiele pausi...\n4  International  Aufständische verwendeten Chemikalie bei Gefec...\n5            Web  Bewährungs- und Geldstrafe für 26-Jährigen weg...\n6          Sport  ÖFB-Teamspieler nur sechs Minuten nach seinem ...\n7       Panorama  Ein 31-jähriger Polizist soll einer 42-Jährige...\n8  International  18 Menschen verschleppt. Kabul – Nach einem Hu...\n9            Web  Deutschland und Frankreich am stärksten von Lo...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target Name</th>\n      <th>Article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wirtschaft</td>\n      <td>'Die Gewerkschaft GPA-djp lanciert den \"All-in...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sport</td>\n      <td>Franzosen verteidigen 2:1-Führung – Kritische ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Web</td>\n      <td>'Neues Video von Designern macht im Netz die R...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sport</td>\n      <td>23-jähriger Brasilianer muss vier Spiele pausi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>International</td>\n      <td>Aufständische verwendeten Chemikalie bei Gefec...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Web</td>\n      <td>Bewährungs- und Geldstrafe für 26-Jährigen weg...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sport</td>\n      <td>ÖFB-Teamspieler nur sechs Minuten nach seinem ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Panorama</td>\n      <td>Ein 31-jähriger Polizist soll einer 42-Jährige...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>International</td>\n      <td>18 Menschen verschleppt. Kabul – Nach einem Hu...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Web</td>\n      <td>Deutschland und Frankreich am stärksten von Lo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test.csv', 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "split_data = []\n",
    "for l in data:\n",
    "    l_split = l.split(';', 1)\n",
    "    split_data.append(l_split)\n",
    "df = pd.DataFrame(split_data, columns=[\"Target Name\", \"Article\"])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'Wirtschaft',\n 1: 'Wissenschaft',\n 2: 'Etat',\n 3: 'Web',\n 4: 'Sport',\n 5: 'International',\n 6: 'Kultur',\n 7: 'Inland',\n 8: 'Panorama'}"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels_map = dict(enumerate(set(df['Target Name'].values)))\n",
    "data_labels_map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "     Target Name                                            Article  \\\n0     Wirtschaft  'Die Gewerkschaft GPA-djp lanciert den \"All-in...   \n1          Sport  Franzosen verteidigen 2:1-Führung – Kritische ...   \n2            Web  'Neues Video von Designern macht im Netz die R...   \n3          Sport  23-jähriger Brasilianer muss vier Spiele pausi...   \n4  International  Aufständische verwendeten Chemikalie bei Gefec...   \n\n                                       Clean Article  \n0  Gewerkschaft gpadjp lancieren allinrechner fin...  \n1  Franzosen verteidigen fuehrung kritisch Stimme...  \n2  neu Video Designer Netz Runde schlagen etwa bu...  \n3  jaehriger Brasilianer vier Spiele pausieren En...  \n4  Aufstaendisch verwenden Chemikalie Gefecht Aug...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target Name</th>\n      <th>Article</th>\n      <th>Clean Article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wirtschaft</td>\n      <td>'Die Gewerkschaft GPA-djp lanciert den \"All-in...</td>\n      <td>Gewerkschaft gpadjp lancieren allinrechner fin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sport</td>\n      <td>Franzosen verteidigen 2:1-Führung – Kritische ...</td>\n      <td>Franzosen verteidigen fuehrung kritisch Stimme...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Web</td>\n      <td>'Neues Video von Designern macht im Netz die R...</td>\n      <td>neu Video Designer Netz Runde schlagen etwa bu...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sport</td>\n      <td>23-jähriger Brasilianer muss vier Spiele pausi...</td>\n      <td>jaehriger Brasilianer vier Spiele pausieren En...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>International</td>\n      <td>Aufständische verwendeten Chemikalie bei Gefec...</td>\n      <td>Aufstaendisch verwenden Chemikalie Gefecht Aug...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus = normalize_corpus(df['Article'], contraction_expansion=False)\n",
    "df['Clean Article'] = norm_corpus\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1028 entries, 0 to 1027\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Target Name    1028 non-null   object\n",
      " 1   Article        1028 non-null   object\n",
      " 2   Clean Article  1028 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 24.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#durch das cleaning leere Dokumente? (Leerzeichen ersetzen)\n",
    "df = df.replace(r'^(\\s?)+$', np.nan, regex=True)\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Bereinigtes Dokument abspeichern\n",
    "df.to_csv('clean_articles.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "((688,), (340,))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dokumente aufteilen 33% testdaten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_corpus, test_corpus,  train_label_names, test_label_names =\\\n",
    "                                 train_test_split(np.array(df['Clean Article']),\n",
    "                                                       np.array(df['Target Name']), test_size=0.33, random_state=42)\n",
    "\n",
    "train_corpus.shape, test_corpus.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "    Target Label  Train Count  Test Count\n3       Panorama          122          46\n7            Web          104          64\n1  International          101          50\n6     Wirtschaft           97          44\n2          Sport           75          45\n0         Inland           71          31\n8   Wissenschaft           45          12\n5           Etat           43          24\n4         Kultur           30          24",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target Label</th>\n      <th>Train Count</th>\n      <th>Test Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>Panorama</td>\n      <td>122</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Web</td>\n      <td>104</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>International</td>\n      <td>101</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Wirtschaft</td>\n      <td>97</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sport</td>\n      <td>75</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Inland</td>\n      <td>71</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Wissenschaft</td>\n      <td>45</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Etat</td>\n      <td>43</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kultur</td>\n      <td>30</td>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wie verteilen sich die Dokumente nach Newsgruppen?\n",
    "#Durchzählen. Sind die Labels gut verteilt in den Train und Testdaten?\n",
    "from collections import Counter\n",
    "\n",
    "trd = dict(Counter(train_label_names))\n",
    "tsd = dict(Counter(test_label_names))\n",
    "\n",
    "(pd.DataFrame([[key, trd[key], tsd[key]] for key in trd],\n",
    "             columns=['Target Label', 'Train Count', 'Test Count'])\n",
    ".sort_values(by=['Train Count', 'Test Count'],\n",
    "             ascending=False))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CountVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# build BOW features on train articles\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# transform test articles into features\n",
    "# HR: der \"fit\" wird übernommen\n",
    "cv_test_features = cv.transform(test_corpus)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (688, 32075)  Test features shape: (340, 32075)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bag of Words\n",
    "ohne Gewichtung der einzelnen Ausdrücke\n",
    "\n",
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.74637681 0.63768116 0.65217391 0.72992701 0.68613139]\n",
      "Mean CV Accuracy: 0.6904580556437109\n",
      "Test Accuracy: 0.6882352941176471\n"
     ]
    }
   ],
   "source": [
    "#HR erste Runde Algorithmen: basierend auf BoW (hier: cv)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB(alpha=1) #Hyperparametr: Alpha versucht zu glätten, indem Wörter nicht so hart bestraft werden, wenn sie nicht oft vorkommen\n",
    "mnb.fit(cv_train_features, train_label_names)\n",
    "mnb_bow_cv_scores = cross_val_score(mnb, cv_train_features, train_label_names, cv=5) # fünf verschiedene Cross Validations\n",
    "mnb_bow_cv_mean_score = np.mean(mnb_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_bow_cv_mean_score)\n",
    "mnb_bow_test_score = mnb.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_bow_test_score) #auf den Testwerten\n",
    "\n",
    "# ungefähr 2/3 Genauigkeit mit einem sehr schnellen Algorithmus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.65217391 0.68115942 0.64492754 0.74452555 0.67883212]\n",
      "Mean CV Accuracy: 0.6803237067597588\n",
      "Test Accuracy: 0.7176470588235294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "lr.fit(cv_train_features, train_label_names)\n",
    "lr_bow_cv_scores = cross_val_score(lr, cv_train_features, train_label_names, cv=5)\n",
    "lr_bow_cv_mean_score = np.mean(lr_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_bow_cv_mean_score)\n",
    "lr_bow_test_score = lr.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_bow_test_score)\n",
    "\n",
    "# vergleichbares Ergebnis aber viel längere Rechenzeit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.68115942 0.66666667 0.63043478 0.66423358 0.67883212]\n",
      "Mean CV Accuracy: 0.6642653125991748\n",
      "Test Accuracy: 0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(cv_train_features, train_label_names)\n",
    "svm_bow_cv_scores = cross_val_score(svm, cv_train_features, train_label_names, cv=5)\n",
    "svm_bow_cv_mean_score = np.mean(svm_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_bow_cv_mean_score)\n",
    "svm_bow_test_score = svm.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_bow_test_score)\n",
    "\n",
    "#wieder ähnliche Genauigkeit und schneller als LR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.70289855 0.60144928 0.65217391 0.65693431 0.64963504]\n",
      "Mean CV Accuracy: 0.6526182164392257\n",
      "Test Accuracy: 0.711764705882353\n"
     ]
    }
   ],
   "source": [
    "# SVM with Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=5, random_state=42)\n",
    "svm_sgd.fit(cv_train_features, train_label_names)\n",
    "svmsgd_bow_cv_scores = cross_val_score(svm_sgd, cv_train_features, train_label_names, cv=5)\n",
    "svmsgd_bow_cv_mean_score = np.mean(svmsgd_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_bow_cv_mean_score)\n",
    "svmsgd_bow_test_score = svm_sgd.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_bow_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.54347826 0.5        0.52173913 0.45255474 0.52554745]\n",
      "Mean CV Accuracy: 0.5086639162170739\n",
      "Test Accuracy: 0.4970588235294118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42) #wie viele parallele Bäume wollen wir erzielen\n",
    "rfc.fit(cv_train_features, train_label_names)\n",
    "rfc_bow_cv_scores = cross_val_score(rfc, cv_train_features, train_label_names, cv=5)\n",
    "rfc_bow_cv_mean_score = np.mean(rfc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_bow_cv_mean_score)\n",
    "rfc_bow_test_score = rfc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_bow_test_score)\n",
    "\n",
    "# haben schlechtere Ergebnisse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.65217391 0.54347826 0.55072464 0.57664234 0.58394161]\n",
      "Mean CV Accuracy: 0.5813921506400085\n",
      "Test Accuracy: 0.5970588235294118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gbc.fit(cv_train_features, train_label_names)\n",
    "gbc_bow_cv_scores = cross_val_score(gbc, cv_train_features, train_label_names, cv=5)\n",
    "gbc_bow_cv_mean_score = np.mean(gbc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_bow_cv_mean_score)\n",
    "gbc_bow_test_score = gbc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_bow_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Jetzt mit TF IDF\n",
    "\n",
    "tf-idf liefert bessere Resultate, da Wörter anders gewichtet (nicht nur Anzahl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "       ab  abaaoud  abbau  abbauen  abbilden  abbildung  abblitzen  abbrechen  \\\n0    0.00      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n1    0.04      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n2    0.04      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n3    0.00      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n4    0.00      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n..    ...      ...    ...      ...       ...        ...        ...        ...   \n335  0.00      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n336  0.00      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n337  0.07      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n338  0.01      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n339  0.03      0.0    0.0      0.0       0.0        0.0        0.0        0.0   \n\n     abc  abd  ...  zwischenstation  zwischenstopp  zwischenzeit  \\\n0    0.0  0.0  ...              0.0            0.0          0.00   \n1    0.0  0.0  ...              0.0            0.0          0.00   \n2    0.0  0.0  ...              0.0            0.0          0.00   \n3    0.0  0.0  ...              0.0            0.0          0.00   \n4    0.0  0.0  ...              0.0            0.0          0.00   \n..   ...  ...  ...              ...            ...           ...   \n335  0.0  0.0  ...              0.0            0.0          0.00   \n336  0.0  0.0  ...              0.0            0.0          0.00   \n337  0.0  0.0  ...              0.0            0.0          0.00   \n338  0.0  0.0  ...              0.0            0.0          0.03   \n339  0.0  0.0  ...              0.0            0.0          0.00   \n\n     zwischenzeitlich  zwoelf  zwoelft  zwoelfte  zyklus  zynisch  zynismus  \n0                 0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n1                 0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n2                 0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n3                 0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n4                 0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n..                ...     ...      ...       ...     ...      ...       ...  \n335               0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n336               0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n337               0.0    0.06      0.0       0.0     0.0      0.0       0.0  \n338               0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n339               0.0    0.00      0.0       0.0     0.0      0.0       0.0  \n\n[340 rows x 19361 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ab</th>\n      <th>abaaoud</th>\n      <th>abbau</th>\n      <th>abbauen</th>\n      <th>abbilden</th>\n      <th>abbildung</th>\n      <th>abblitzen</th>\n      <th>abbrechen</th>\n      <th>abc</th>\n      <th>abd</th>\n      <th>...</th>\n      <th>zwischenstation</th>\n      <th>zwischenstopp</th>\n      <th>zwischenzeit</th>\n      <th>zwischenzeitlich</th>\n      <th>zwoelf</th>\n      <th>zwoelft</th>\n      <th>zwoelfte</th>\n      <th>zyklus</th>\n      <th>zynisch</th>\n      <th>zynismus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>335</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>336</th>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>0.07</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.06</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.03</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>0.03</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>340 rows × 19361 columns</p>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1.,use_idf=True)\n",
    "tv_matrix = tv.fit_transform(test_corpus) #TfidfVectoriuzer kombiniert beide Formeln, weshalb man hier die Grundsätze importieren kann\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names_out()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# build BOW features on train articles\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# transform test articles into features\n",
    "tv_test_features = tv.transform(test_corpus)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF model:> Train features shape: (688, 32075)  Test features shape: (340, 32075)\n"
     ]
    }
   ],
   "source": [
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.50724638 0.44927536 0.47101449 0.46715328 0.51824818]\n",
      "Mean CV Accuracy: 0.4825875383476145\n",
      "Test Accuracy: 0.5088235294117647\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(tv_train_features, train_label_names)\n",
    "mnb_tfidf_cv_scores = cross_val_score(mnb, tv_train_features, train_label_names, cv=5)\n",
    "mnb_tfidf_cv_mean_score = np.mean(mnb_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_tfidf_cv_mean_score)\n",
    "mnb_tfidf_test_score = mnb.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_tfidf_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.64492754 0.5942029  0.5942029  0.6350365  0.58394161]\n",
      "Mean CV Accuracy: 0.6104622871046228\n",
      "Test Accuracy: 0.6558823529411765\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "lr.fit(tv_train_features, train_label_names)\n",
    "lr_tfidf_cv_scores = cross_val_score(lr, tv_train_features, train_label_names, cv=5)\n",
    "lr_tfidf_cv_mean_score = np.mean(lr_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_tfidf_cv_mean_score)\n",
    "lr_tfidf_test_score = lr.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_tfidf_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.77536232 0.73913043 0.73913043 0.75182482 0.70072993]\n",
      "Mean CV Accuracy: 0.7412355865862689\n",
      "Test Accuracy: 0.8147058823529412\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "svm_tfidf_cv_scores = cross_val_score(svm, tv_train_features, train_label_names, cv=5)\n",
    "svm_tfidf_cv_mean_score = np.mean(svm_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_tfidf_cv_mean_score)\n",
    "svm_tfidf_test_score = svm.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_tfidf_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.75362319 0.69565217 0.69565217 0.7080292  0.72262774]\n",
      "Mean CV Accuracy: 0.7151168941076906\n",
      "Test Accuracy: 0.788235294117647\n"
     ]
    }
   ],
   "source": [
    "svm_sgd = SGDClassifier(loss='hinge', penalty='l2', max_iter=5, random_state=42)\n",
    "svm_sgd.fit(tv_train_features, train_label_names)\n",
    "svmsgd_tfidf_cv_scores = cross_val_score(svm_sgd, tv_train_features, train_label_names, cv=5)\n",
    "svmsgd_tfidf_cv_mean_score = np.mean(svmsgd_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_tfidf_cv_mean_score)\n",
    "svmsgd_tfidf_test_score = svm_sgd.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_tfidf_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.49275362 0.47101449 0.51449275 0.50364964 0.48175182]\n",
      "Mean CV Accuracy: 0.49273246588384645\n",
      "Test Accuracy: 0.4823529411764706\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(tv_train_features, train_label_names)\n",
    "rfc_tfidf_cv_scores = cross_val_score(rfc, tv_train_features, train_label_names, cv=5)\n",
    "rfc_tfidf_cv_mean_score = np.mean(rfc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_tfidf_cv_mean_score)\n",
    "rfc_tfidf_test_score = rfc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_tfidf_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.5942029  0.55072464 0.56521739 0.59124088 0.54744526]\n",
      "Mean CV Accuracy: 0.5697662117846186\n",
      "Test Accuracy: 0.5441176470588235\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gbc.fit(tv_train_features, train_label_names)\n",
    "gbc_tfidf_cv_scores = cross_val_score(gbc, tv_train_features, train_label_names, cv=5)\n",
    "gbc_tfidf_cv_mean_score = np.mean(gbc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_tfidf_cv_mean_score)\n",
    "gbc_tfidf_test_score = gbc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_tfidf_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ergebnisübersicht"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "                               0                    1           2  \\\nModel                Naive Bayes  Logistic Regression  Linear SVM   \nCV Score (TF)           0.690458             0.680324    0.664265   \nTest Score (TF)         0.688235             0.717647    0.705882   \nCV Score (TF-IDF)       0.482588             0.610462    0.741236   \nTest Score (TF-IDF)     0.508824             0.655882    0.814706   \n\n                                    3              4  \\\nModel                Linear SVM (SGD)  Random Forest   \nCV Score (TF)                0.652618       0.508664   \nTest Score (TF)              0.711765       0.497059   \nCV Score (TF-IDF)            0.715117       0.492732   \nTest Score (TF-IDF)          0.788235       0.482353   \n\n                                             5  \nModel                Gradient Boosted Machines  \nCV Score (TF)                         0.581392  \nTest Score (TF)                       0.597059  \nCV Score (TF-IDF)                     0.569766  \nTest Score (TF-IDF)                   0.544118  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Model</th>\n      <td>Naive Bayes</td>\n      <td>Logistic Regression</td>\n      <td>Linear SVM</td>\n      <td>Linear SVM (SGD)</td>\n      <td>Random Forest</td>\n      <td>Gradient Boosted Machines</td>\n    </tr>\n    <tr>\n      <th>CV Score (TF)</th>\n      <td>0.690458</td>\n      <td>0.680324</td>\n      <td>0.664265</td>\n      <td>0.652618</td>\n      <td>0.508664</td>\n      <td>0.581392</td>\n    </tr>\n    <tr>\n      <th>Test Score (TF)</th>\n      <td>0.688235</td>\n      <td>0.717647</td>\n      <td>0.705882</td>\n      <td>0.711765</td>\n      <td>0.497059</td>\n      <td>0.597059</td>\n    </tr>\n    <tr>\n      <th>CV Score (TF-IDF)</th>\n      <td>0.482588</td>\n      <td>0.610462</td>\n      <td>0.741236</td>\n      <td>0.715117</td>\n      <td>0.492732</td>\n      <td>0.569766</td>\n    </tr>\n    <tr>\n      <th>Test Score (TF-IDF)</th>\n      <td>0.508824</td>\n      <td>0.655882</td>\n      <td>0.814706</td>\n      <td>0.788235</td>\n      <td>0.482353</td>\n      <td>0.544118</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['Naive Bayes', mnb_bow_cv_mean_score, mnb_bow_test_score,\n",
    "               mnb_tfidf_cv_mean_score, mnb_tfidf_test_score],\n",
    "              ['Logistic Regression', lr_bow_cv_mean_score, lr_bow_test_score,\n",
    "               lr_tfidf_cv_mean_score, lr_tfidf_test_score],\n",
    "              ['Linear SVM', svm_bow_cv_mean_score, svm_bow_test_score,\n",
    "               svm_tfidf_cv_mean_score, svm_tfidf_test_score],\n",
    "              ['Linear SVM (SGD)', svmsgd_bow_cv_mean_score, svmsgd_bow_test_score,\n",
    "               svmsgd_tfidf_cv_mean_score, svmsgd_tfidf_test_score],\n",
    "              ['Random Forest', rfc_bow_cv_mean_score, rfc_bow_test_score,\n",
    "               rfc_tfidf_cv_mean_score, rfc_tfidf_test_score],\n",
    "              ['Gradient Boosted Machines', gbc_bow_cv_mean_score, gbc_bow_test_score,\n",
    "               gbc_tfidf_cv_mean_score, gbc_tfidf_test_score]],\n",
    "             columns=['Model', 'CV Score (TF)', 'Test Score (TF)', 'CV Score (TF-IDF)', 'Test Score (TF-IDF)'],\n",
    "             ).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# Hyperparameter-Tuning\n",
    "### Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.4s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.5s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.4s\n",
      "[CV] END ........mnb__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.4s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.5s\n",
      "[CV] END .......mnb__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.5s\n",
      "[CV] END .........mnb__alpha=0.01, tfidf__ngram_range=(1, 2); total time=   0.5s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.1s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.4s\n",
      "[CV] END ..........mnb__alpha=0.1, tfidf__ngram_range=(1, 2); total time=   0.5s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ............mnb__alpha=1, tfidf__ngram_range=(1, 2); total time=   0.4s\n"
     ]
    }
   ],
   "source": [
    "#hier startet das Hyperparameter-Tuning\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV #alle Kombinationen der Parameter werden versucht\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #nehmen nur noch das TFIDF, da dies bessere Resultate geliefert hat\n",
    "\n",
    "mnb_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('mnb', MultinomialNB())\n",
    "                       ])\n",
    "\n",
    "#die Parameter, die durchprobiert werden sollen: 1/2-gramme und alpha-smoothing\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],       #2 Möglichkeiten\n",
    "              'mnb__alpha': [1e-5, 1e-4, 1e-2, 1e-1, 1]     #5 Möglichkeiten von 1 Zehntausenstel\n",
    "}\n",
    "\n",
    "# 2*5 Möglichkeiten, welche 5 Mal (cv) ausprobiert werden = 50 Durchläufe\n",
    "gs_mnb = GridSearchCV(mnb_pipeline, param_grid, cv=5, verbose=2) # jedes fünf Mal ausprobieren, Verbose -> Auskunft geben, was passiert\n",
    "gs_mnb = gs_mnb.fit(train_corpus, train_label_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('tfidf', TfidfVectorizer()), ('mnb', MultinomialNB(alpha=0.01))],\n 'verbose': False,\n 'tfidf': TfidfVectorizer(),\n 'mnb': MultinomialNB(alpha=0.01),\n 'tfidf__analyzer': 'word',\n 'tfidf__binary': False,\n 'tfidf__decode_error': 'strict',\n 'tfidf__dtype': numpy.float64,\n 'tfidf__encoding': 'utf-8',\n 'tfidf__input': 'content',\n 'tfidf__lowercase': True,\n 'tfidf__max_df': 1.0,\n 'tfidf__max_features': None,\n 'tfidf__min_df': 1,\n 'tfidf__ngram_range': (1, 1),\n 'tfidf__norm': 'l2',\n 'tfidf__preprocessor': None,\n 'tfidf__smooth_idf': True,\n 'tfidf__stop_words': None,\n 'tfidf__strip_accents': None,\n 'tfidf__sublinear_tf': False,\n 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n 'tfidf__tokenizer': None,\n 'tfidf__use_idf': True,\n 'tfidf__vocabulary': None,\n 'mnb__alpha': 0.01,\n 'mnb__class_prior': None,\n 'mnb__fit_prior': True,\n 'mnb__force_alpha': 'warn'}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#beste Parameter?\n",
    "gs_mnb.best_estimator_.get_params()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "   rank                                                params  \\\n4     1    {'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 1)}   \n3     2  {'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 2)}   \n2     3  {'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 1)}   \n1     4   {'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 2)}   \n5     5    {'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 2)}   \n0     6   {'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 1)}   \n6     7     {'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 1)}   \n7     8     {'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 2)}   \n8     9       {'mnb__alpha': 1, 'tfidf__ngram_range': (1, 1)}   \n9    10       {'mnb__alpha': 1, 'tfidf__ngram_range': (1, 2)}   \n\n   cv score (mean)  cv score (std)  \n4         0.752914        0.022834  \n3         0.731133        0.021149  \n2         0.725346        0.028260  \n1         0.719496        0.025944  \n5         0.709341        0.037791  \n0         0.706464        0.025444  \n6         0.662827        0.030921  \n7         0.626500        0.035527  \n8         0.507278        0.028619  \n9         0.469470        0.030585  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>params</th>\n      <th>cv score (mean)</th>\n      <th>cv score (std)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>{'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 1)}</td>\n      <td>0.752914</td>\n      <td>0.022834</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>{'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 2)}</td>\n      <td>0.731133</td>\n      <td>0.021149</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>{'mnb__alpha': 0.0001, 'tfidf__ngram_range': (1, 1)}</td>\n      <td>0.725346</td>\n      <td>0.028260</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>{'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 2)}</td>\n      <td>0.719496</td>\n      <td>0.025944</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>{'mnb__alpha': 0.01, 'tfidf__ngram_range': (1, 2)}</td>\n      <td>0.709341</td>\n      <td>0.037791</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>{'mnb__alpha': 1e-05, 'tfidf__ngram_range': (1, 1)}</td>\n      <td>0.706464</td>\n      <td>0.025444</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>{'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 1)}</td>\n      <td>0.662827</td>\n      <td>0.030921</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>{'mnb__alpha': 0.1, 'tfidf__ngram_range': (1, 2)}</td>\n      <td>0.626500</td>\n      <td>0.035527</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>{'mnb__alpha': 1, 'tfidf__ngram_range': (1, 1)}</td>\n      <td>0.507278</td>\n      <td>0.028619</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>{'mnb__alpha': 1, 'tfidf__ngram_range': (1, 2)}</td>\n      <td>0.469470</td>\n      <td>0.030585</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb.best_estimator_.get_params()\n",
    "#Rangfolge\n",
    "\n",
    "cv_results = gs_mnb.cv_results_\n",
    "results_df = pd.DataFrame({'rank': cv_results['rank_test_score'],\n",
    "                           'params': cv_results['params'],\n",
    "                           'cv score (mean)': cv_results['mean_test_score'],\n",
    "                           'cv score (std)': cv_results['std_test_score']}\n",
    "                          )\n",
    "results_df = results_df.sort_values(by=['rank'], ascending=True)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "results_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.8\n"
     ]
    }
   ],
   "source": [
    "#und wie gut geht es für die Testdaten?\n",
    "best_mnb_test_score = gs_mnb.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_mnb_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 1); total time=   1.8s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 1); total time=   1.5s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 1); total time=   1.4s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 2); total time=   6.7s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 2); total time=   5.7s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 2); total time=   5.9s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 2); total time=   5.8s\n",
      "[CV] END .................lr__C=1, tfidf__ngram_range=(1, 2); total time=   5.8s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 1); total time=   1.7s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 1); total time=   2.7s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 1); total time=   2.1s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 2); total time=   7.6s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 2); total time=   7.9s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 2); total time=   8.8s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 2); total time=  10.4s\n",
      "[CV] END .................lr__C=5, tfidf__ngram_range=(1, 2); total time=   8.2s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 1); total time=   2.2s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 1); total time=   2.1s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 1); total time=   2.2s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 2); total time=   9.9s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 2); total time=   9.3s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 2); total time=  12.1s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 2); total time=  14.3s\n",
      "[CV] END ................lr__C=10, tfidf__ngram_range=(1, 2); total time=  10.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('lr', LogisticRegression(penalty='l2', max_iter=100, random_state=42))\n",
    "                       ])\n",
    "\n",
    "#C-Wert steuert Regularisierung = Bestrafung von over-fitting\n",
    "# komplexe Funktion wird weniger gut bewertet als einfache\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'lr__C': [1, 5, 10]                   #könnte sich lohnen, über 10 hinausgehen\n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(lr_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_lr = gs_lr.fit(train_corpus, train_label_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n                ('lr', LogisticRegression(C=10, random_state=42))])",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n                (&#x27;lr&#x27;, LogisticRegression(C=10, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n                (&#x27;lr&#x27;, LogisticRegression(C=10, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, random_state=42)</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.7676470588235295\n"
     ]
    }
   ],
   "source": [
    "best_lr_test_score = gs_lr.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_lr_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .............svm__C=0.01, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ..............svm__C=0.1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 2); total time=   0.4s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=1, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ................svm__C=5, tfidf__ngram_range=(1, 2); total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('svm', LinearSVC(random_state=42))\n",
    "                       ])\n",
    "\n",
    "#C-Wert - siehe oben\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'svm__C': [0.01, 0.1, 1, 5]\n",
    "}\n",
    "\n",
    "gs_svm = GridSearchCV(svm_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_svm = gs_svm.fit(train_corpus, train_label_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('tfidf', TfidfVectorizer()),\n  ('svm', LinearSVC(C=1, random_state=42))],\n 'verbose': False,\n 'tfidf': TfidfVectorizer(),\n 'svm': LinearSVC(C=1, random_state=42),\n 'tfidf__analyzer': 'word',\n 'tfidf__binary': False,\n 'tfidf__decode_error': 'strict',\n 'tfidf__dtype': numpy.float64,\n 'tfidf__encoding': 'utf-8',\n 'tfidf__input': 'content',\n 'tfidf__lowercase': True,\n 'tfidf__max_df': 1.0,\n 'tfidf__max_features': None,\n 'tfidf__min_df': 1,\n 'tfidf__ngram_range': (1, 1),\n 'tfidf__norm': 'l2',\n 'tfidf__preprocessor': None,\n 'tfidf__smooth_idf': True,\n 'tfidf__stop_words': None,\n 'tfidf__strip_accents': None,\n 'tfidf__sublinear_tf': False,\n 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n 'tfidf__tokenizer': None,\n 'tfidf__use_idf': True,\n 'tfidf__vocabulary': None,\n 'svm__C': 1,\n 'svm__class_weight': None,\n 'svm__dual': 'warn',\n 'svm__fit_intercept': True,\n 'svm__intercept_scaling': 1,\n 'svm__loss': 'squared_hinge',\n 'svm__max_iter': 1000,\n 'svm__multi_class': 'ovr',\n 'svm__penalty': 'l2',\n 'svm__random_state': 42,\n 'svm__tol': 0.0001,\n 'svm__verbose': 0}"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_.get_params()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.8147058823529412\n"
     ]
    }
   ],
   "source": [
    "best_svm_test_score = gs_svm.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_svm_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 2); total time=   0.4s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 2); total time=   0.4s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 2); total time=   0.5s\n",
      "[CV] END ........sgd__alpha=1e-07, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 2); total time=   0.2s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-06, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END ........sgd__alpha=1e-05, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 1); total time=   0.0s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.3s\n",
      "[CV] END .......sgd__alpha=0.0001, tfidf__ngram_range=(1, 2); total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "sgd_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                        ('sgd', SGDClassifier(random_state=42))\n",
    "                       ])\n",
    "\n",
    "#alpha-Wert: Regularisierungsfaktor\n",
    "param_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'sgd__alpha': [1e-7, 1e-6, 1e-5, 1e-4]\n",
    "}\n",
    "\n",
    "gs_sgd = GridSearchCV(sgd_pipeline, param_grid, cv=5, verbose=2)\n",
    "gs_sgd = gs_sgd.fit(train_corpus, train_label_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n  ('sgd', SGDClassifier(alpha=1e-05, random_state=42))],\n 'verbose': False,\n 'tfidf': TfidfVectorizer(ngram_range=(1, 2)),\n 'sgd': SGDClassifier(alpha=1e-05, random_state=42),\n 'tfidf__analyzer': 'word',\n 'tfidf__binary': False,\n 'tfidf__decode_error': 'strict',\n 'tfidf__dtype': numpy.float64,\n 'tfidf__encoding': 'utf-8',\n 'tfidf__input': 'content',\n 'tfidf__lowercase': True,\n 'tfidf__max_df': 1.0,\n 'tfidf__max_features': None,\n 'tfidf__min_df': 1,\n 'tfidf__ngram_range': (1, 2),\n 'tfidf__norm': 'l2',\n 'tfidf__preprocessor': None,\n 'tfidf__smooth_idf': True,\n 'tfidf__stop_words': None,\n 'tfidf__strip_accents': None,\n 'tfidf__sublinear_tf': False,\n 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n 'tfidf__tokenizer': None,\n 'tfidf__use_idf': True,\n 'tfidf__vocabulary': None,\n 'sgd__alpha': 1e-05,\n 'sgd__average': False,\n 'sgd__class_weight': None,\n 'sgd__early_stopping': False,\n 'sgd__epsilon': 0.1,\n 'sgd__eta0': 0.0,\n 'sgd__fit_intercept': True,\n 'sgd__l1_ratio': 0.15,\n 'sgd__learning_rate': 'optimal',\n 'sgd__loss': 'hinge',\n 'sgd__max_iter': 1000,\n 'sgd__n_iter_no_change': 5,\n 'sgd__n_jobs': None,\n 'sgd__penalty': 'l2',\n 'sgd__power_t': 0.5,\n 'sgd__random_state': 42,\n 'sgd__shuffle': True,\n 'sgd__tol': 0.001,\n 'sgd__validation_fraction': 0.1,\n 'sgd__verbose': 0,\n 'sgd__warm_start': False}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_sgd.best_estimator_.get_params()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.7794117647058824\n"
     ]
    }
   ],
   "source": [
    "best_sgd_test_score = gs_sgd.score(test_corpus, test_label_names)\n",
    "print('Test Accuracy :', best_sgd_test_score)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'model_evaluation_utils_hr' from 'C:\\\\Users\\\\sarak\\\\Documents\\\\FHGR\\\\NLP\\\\notebooks\\\\model_evaluation_utils_hr.py'>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_evaluation_utils_hr as meu\n",
    "import importlib\n",
    "importlib.reload(meu)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyse der Ergebnisse für MNB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "Precision: 0.8201\n",
      "Recall: 0.8\n",
      "F1 Score: 0.8009\n"
     ]
    }
   ],
   "source": [
    "# Auswahl aufgrund guter Ergebnisse und einfaches Handling\n",
    "\n",
    "mnb_predictions = gs_mnb.predict(test_corpus)\n",
    "unique_classes = list(set(test_label_names))\n",
    "meu.get_metrics(true_labels=test_label_names, predicted_labels=mnb_predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Wirtschaft       0.76      0.80      0.78        44\n",
      " Wissenschaft       0.83      0.83      0.83        12\n",
      "         Etat       1.00      0.50      0.67        24\n",
      "          Web       0.93      0.88      0.90        64\n",
      "        Sport       0.98      0.89      0.93        45\n",
      "International       0.80      0.82      0.81        50\n",
      "       Kultur       0.75      0.62      0.68        24\n",
      "       Inland       0.69      0.87      0.77        31\n",
      "     Panorama       0.61      0.78      0.69        46\n",
      "\n",
      "     accuracy                           0.80       340\n",
      "    macro avg       0.82      0.78      0.78       340\n",
      " weighted avg       0.82      0.80      0.80       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ergebnisse nach Newsgruppe\n",
    "\n",
    "meu.display_classification_report(true_labels=test_label_names,\n",
    "                                  predicted_labels=mnb_predictions, classes=unique_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "      Label Name  Label Number\n0     Wirtschaft             0\n1   Wissenschaft             1\n2           Etat             2\n3            Web             3\n4          Sport             4\n5  International             5\n6         Kultur             6\n7         Inland             7\n8       Panorama             8",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label Name</th>\n      <th>Label Number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wirtschaft</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wissenschaft</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Etat</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Web</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sport</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>International</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Kultur</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Inland</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Panorama</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Übersicht Label\n",
    "\n",
    "label_data_map = {v:k for k, v in data_labels_map.items()}\n",
    "label_map_df = pd.DataFrame(list(label_data_map.items()), columns=['Label Name', 'Label Number'])\n",
    "label_map_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "                      Predicted:                                            \\\n                      Wirtschaft Wissenschaft Etat Web Sport International   \nActual: Wirtschaft            12            4    1   4     1             0   \n        Wissenschaft           0           27    0   0     1             0   \n        Etat                   0            0   41   0     8             0   \n        Web                    0            2    1  15     4             0   \n        Sport                  0            3    3   1    36             0   \n        International          0            0    2   0     3            40   \n        Kultur                 0            1    1   0     2             0   \n        Inland                 0            1    1   0     4             1   \n        Panorama               0            1    1   0     0             0   \n\n                                              \n                      Kultur Inland Panorama  \nActual: Wirtschaft         1      0        1  \n        Wissenschaft       0      3        0  \n        Etat               0      1        0  \n        Web                1      0        1  \n        Sport              0      3        0  \n        International      0      0        0  \n        Kultur            56      4        0  \n        Inland             2     35        0  \n        Panorama           0      0       10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"9\" halign=\"left\">Predicted:</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>Wirtschaft</th>\n      <th>Wissenschaft</th>\n      <th>Etat</th>\n      <th>Web</th>\n      <th>Sport</th>\n      <th>International</th>\n      <th>Kultur</th>\n      <th>Inland</th>\n      <th>Panorama</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"9\" valign=\"top\">Actual:</th>\n      <th>Wirtschaft</th>\n      <td>12</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Wissenschaft</th>\n      <td>0</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Etat</th>\n      <td>0</td>\n      <td>0</td>\n      <td>41</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Web</th>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>15</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Sport</th>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>International</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Kultur</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>56</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Inland</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>35</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Panorama</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Konfusionsmatrix mit Labeln\n",
    "unique_classes = label_map_df['Label Name'].values\n",
    "meu.display_confusion_matrix_pretty(true_labels=test_label_names,\n",
    "                                    predicted_labels=mnb_predictions, classes=unique_classes)\n",
    "\n",
    "# vieles, die ETAT sind, sind auch in Sport eingeordnet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 428,  533,  388,  107,  423,  420,  158,  237,  662,  543,  923,\n         31,  394,  582,  914, 1025,  309,  688,  588,  244,  801,  750,\n        755,  506,  350,  872,  745,   96,  286,  382,  449,  993,  531,\n        696,  101,  261,  832,  109,   70,   59,  657,  902,  136,  910,\n        580,  168,  652,   86,  903,  758,  974,  359,  706,  851,  538,\n        405,  296,  323,  633,   10,  549,  718,  790,  139,  842,  208,\n        846,  835,  290,   76,  595,  700,   30,  615,  760,   54,   23,\n        526,  468,  518,    3,  798, 1022,  616,  409,  451,  894,  649,\n        411,  535,  996,  596,  199,  527,  998,  318,  430,  825,   39,\n        764,  770,  677,  673,  898,   66,  717,   67,  260,  209,  613,\n        361,  665,  806,  493,  830,  362,  210,  675,  723,  956,  762,\n        100,  298,   88,   63,  906,  678,  924,  256,  626,  332,  314,\n          2,  803,  275,  398,  982,  432,  861,  499,  536,  823,  901,\n        572,  184,  731,  966,  479,  841,  847,  630,  218,  174,  880,\n        289,  106,  551,   55,  120,  516,   25,   72,  462,   44,  501,\n        707,  310,  743,  333,  548,  930,  947,  352,  670,  198,  845,\n        601,  299,  991,  344,  312,  327,   60,  321,  495,   92,  621,\n        485,  440,  213,  192,  618,  294,  328,  334,  915,  453,  351,\n        477,  247,  110,  593,  522,  371,  984,  277,  622,  265,  589,\n        467,  650,  927, 1015,  756,  137,  945, 1011,  306,  778,  933,\n        578,  231,  816,  215,  753,  448,  964, 1014,  850,  381,   78,\n         29,  307,  545,   49,  668, 1016,  547,  165,  584,  178,  980,\n         65,  141,  603,  365,  857,  436,  342,  692,  972,  557,  737,\n        254,  221,  280,  235,  336,  567,  935,  249,  558,  377,   71,\n         94,   33,  259,  204,  355,  599,  687,   77,   84,  720,   82,\n        380,  604,  664,  541,  532,  424,  305,    5,  442,  605,   97,\n        292,  404,  679,  899,  281,  266,  854,  513,  331,  893,  907,\n        544,  118,  938,  250,  827,  792,    9,  970,  196,  629,   81,\n        685,  534,  828,  239,  319,  211,  746,  530,  751,  227,  887,\n        457,  826,  177,  969,  429,  986,  514,  346,  705,    7,  155,\n        786,  481,  329,  519,  439,  807,  590,  949,  602,  968])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(np.array(range(len(df['Article']))), test_size=0.33, random_state=42)\n",
    "test_idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "      Target Name  \\\n428    Wirtschaft   \n533    Wirtschaft   \n388          Etat   \n107  Wissenschaft   \n423         Sport   \n\n                                                                                                                                                                                                     Article  \\\n428  'Finanzminister Osborne sieht \"Jahre der Rezession\" – Österreichs Wirtschaft geht nicht von Brexit aus. Wien/London – Knapp fünf Wochen vor der Volksabstimmung in Großbritannien über Verbleib in o...   \n533  Österreichs Automobilindustrie sieht sich gut aufgestellt und macht gegen die Verteufelung des Autos mobil. Wien/Graz/Aurora –  Die heimische Automobilindustrie zeigt sich selbstbewusst: Während d...   \n388  Ein halbes Jahr nach dem DVD-Start zeigt der ORF ab Montag Schalkos bildgewaltige Miniserie. Wien – Diese Frage musste ja kommen, sagt Produzent John Lueftner. Mit den Vorstadtweibern, nein, mit d...   \n107  Techniker ringen mit einem Problem diesseits von Higgs-Bosonen und Dunkler Materie. Genf – Mit dem Nachweis des Higgs-Bosons schrieb das Genfer Teilchenforschungszentrum Cern 2012 Wissenschaftsges...   \n423  5:2 erster Erfolg bei einer A-WM seit 1939 – Russland, Kanada, Finnland im Viertelfinale – Kasachstan steht als Absteiger fest. St. Petersburg/Moskau – Gastgeber Russland, Titelverteidiger Kanada ...   \n\n                                                                                                                                                                                               Clean Article  \\\n428  Finanzminister Osborne sehen Jahr Rezession oesterreichs Wirtschaft gehen Brexit wien London knapp Fuenf Wochen Volksabstimmung Grobritannien Ueber verbleib ausscheiden EU nehmen warnend Stimme so...   \n533  oesterreichs Automobilindustrie sehen gut aufstellen Verteufelung Auto mobil Wien Graz Aurora heimisch Automobilindustrie zeigen selbstbewusst waehrend Wirtschaftsstandort Oesterreich Ranking perm...   \n388  halb Jahr dvdstart zeigen Orf ab Montag Schalkos bildgewaltig Miniserie wien Frage ja kommen sagen produzent John Lueftner Vorstadtweiber nein Moecht messen Traumquote geben kantig Orf zeigen ab M...   \n107  Techniker ringen Problem diesseits higgsbosonen dunkel Materie Genf nachweis higgsbosons schreiben Genfer Teilchenforschungszentrum Cern Wissenschaftsgeschichte Plaene Fuer Zukunft ehrgeizig hoffe...   \n423  erster Erfolg awm seit russland kanada Finnland Viertelfinale Kasachstan stehen Absteiger fest st Petersburg Moskau Gastgeber russland Titelverteidiger Kanada Mitfavorit Finnland eishockeywm tsche...   \n\n    Predicted Name  Predicted Confidence  \n428     Wirtschaft              0.563171  \n533     Wirtschaft              0.779896  \n388           Etat              0.732100  \n107   Wissenschaft              0.665455  \n423          Sport              0.999968  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target Name</th>\n      <th>Article</th>\n      <th>Clean Article</th>\n      <th>Predicted Name</th>\n      <th>Predicted Confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>428</th>\n      <td>Wirtschaft</td>\n      <td>'Finanzminister Osborne sieht \"Jahre der Rezession\" – Österreichs Wirtschaft geht nicht von Brexit aus. Wien/London – Knapp fünf Wochen vor der Volksabstimmung in Großbritannien über Verbleib in o...</td>\n      <td>Finanzminister Osborne sehen Jahr Rezession oesterreichs Wirtschaft gehen Brexit wien London knapp Fuenf Wochen Volksabstimmung Grobritannien Ueber verbleib ausscheiden EU nehmen warnend Stimme so...</td>\n      <td>Wirtschaft</td>\n      <td>0.563171</td>\n    </tr>\n    <tr>\n      <th>533</th>\n      <td>Wirtschaft</td>\n      <td>Österreichs Automobilindustrie sieht sich gut aufgestellt und macht gegen die Verteufelung des Autos mobil. Wien/Graz/Aurora –  Die heimische Automobilindustrie zeigt sich selbstbewusst: Während d...</td>\n      <td>oesterreichs Automobilindustrie sehen gut aufstellen Verteufelung Auto mobil Wien Graz Aurora heimisch Automobilindustrie zeigen selbstbewusst waehrend Wirtschaftsstandort Oesterreich Ranking perm...</td>\n      <td>Wirtschaft</td>\n      <td>0.779896</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>Etat</td>\n      <td>Ein halbes Jahr nach dem DVD-Start zeigt der ORF ab Montag Schalkos bildgewaltige Miniserie. Wien – Diese Frage musste ja kommen, sagt Produzent John Lueftner. Mit den Vorstadtweibern, nein, mit d...</td>\n      <td>halb Jahr dvdstart zeigen Orf ab Montag Schalkos bildgewaltig Miniserie wien Frage ja kommen sagen produzent John Lueftner Vorstadtweiber nein Moecht messen Traumquote geben kantig Orf zeigen ab M...</td>\n      <td>Etat</td>\n      <td>0.732100</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>Wissenschaft</td>\n      <td>Techniker ringen mit einem Problem diesseits von Higgs-Bosonen und Dunkler Materie. Genf – Mit dem Nachweis des Higgs-Bosons schrieb das Genfer Teilchenforschungszentrum Cern 2012 Wissenschaftsges...</td>\n      <td>Techniker ringen Problem diesseits higgsbosonen dunkel Materie Genf nachweis higgsbosons schreiben Genfer Teilchenforschungszentrum Cern Wissenschaftsgeschichte Plaene Fuer Zukunft ehrgeizig hoffe...</td>\n      <td>Wissenschaft</td>\n      <td>0.665455</td>\n    </tr>\n    <tr>\n      <th>423</th>\n      <td>Sport</td>\n      <td>5:2 erster Erfolg bei einer A-WM seit 1939 – Russland, Kanada, Finnland im Viertelfinale – Kasachstan steht als Absteiger fest. St. Petersburg/Moskau – Gastgeber Russland, Titelverteidiger Kanada ...</td>\n      <td>erster Erfolg awm seit russland kanada Finnland Viertelfinale Kasachstan stehen Absteiger fest st Petersburg Moskau Gastgeber russland Titelverteidiger Kanada Mitfavorit Finnland eishockeywm tsche...</td>\n      <td>Sport</td>\n      <td>0.999968</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#einige Beispiele\n",
    "\n",
    "predict_probas = gs_mnb.predict_proba(test_corpus).max(axis=1)\n",
    "test_df = df.iloc[test_idx]\n",
    "test_df['Predicted Name'] = mnb_predictions\n",
    "test_df['Predicted Confidence'] = predict_probas\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "    Target Name  \\\n923       Sport   \n760       Sport   \n\n                                                                                                                                                                                                     Article  \\\n923  Treffen in Zürich soll am 16. Dezember stattfinden. Wien – Der Weltfußballverband Fifa dürfte am 16. Dezember über die Nachfolge seines zurückgetretenen Präsidenten Sepp Blatter entscheiden. Das b...   \n760  Am 28. November verteidigt der Ukrainer in der Düsseldorf-Arena alle vier WM-Titel. Die Vorbereitung findet traditionell beim Stanglwirt in Going statt. Going – Es hat schon Tradition, dass sich W...   \n\n                                                                                                                                                                                               Clean Article  \\\n923  Treffen Zuerich sollen Dezember stattfinden wien Weltfuballverband Fifa Duerfte Dezember Ueber Nachfolge zurueckgetretenen Praesident Sepp Blatter entscheiden berichten bbc Mittwochfrueh Mitglieds...   \n760  November verteidigen Ukrainer duesseldorfarena vier wmtitel Vorbereitung finden traditionell Stanglwirt Going statt Going schon Tradition Wladimir Klitschko Tiroler bergen Stanglwirt Going wmkaemp...   \n\n    Predicted Name  Predicted Confidence  \n923  International              0.643908  \n760  International              0.429052  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target Name</th>\n      <th>Article</th>\n      <th>Clean Article</th>\n      <th>Predicted Name</th>\n      <th>Predicted Confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>923</th>\n      <td>Sport</td>\n      <td>Treffen in Zürich soll am 16. Dezember stattfinden. Wien – Der Weltfußballverband Fifa dürfte am 16. Dezember über die Nachfolge seines zurückgetretenen Präsidenten Sepp Blatter entscheiden. Das b...</td>\n      <td>Treffen Zuerich sollen Dezember stattfinden wien Weltfuballverband Fifa Duerfte Dezember Ueber Nachfolge zurueckgetretenen Praesident Sepp Blatter entscheiden berichten bbc Mittwochfrueh Mitglieds...</td>\n      <td>International</td>\n      <td>0.643908</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>Sport</td>\n      <td>Am 28. November verteidigt der Ukrainer in der Düsseldorf-Arena alle vier WM-Titel. Die Vorbereitung findet traditionell beim Stanglwirt in Going statt. Going – Es hat schon Tradition, dass sich W...</td>\n      <td>November verteidigen Ukrainer duesseldorfarena vier wmtitel Vorbereitung finden traditionell Stanglwirt Going statt Going schon Tradition Wladimir Klitschko Tiroler bergen Stanglwirt Going wmkaemp...</td>\n      <td>International</td>\n      <td>0.429052</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#falsch einsortierte Dokumente\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "res_df = (test_df[(test_df['Target Name'] == 'Sport') & (test_df['Predicted Name'] == 'International')]\n",
    "       .sort_values(by=['Predicted Confidence'], ascending=False).head(5))\n",
    "res_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "    Target Name  \\\n705       Sport   \n798       Sport   \n801       Sport   \n\n                                                                                                                                                                                                     Article  \\\n705  Michael Diamond betrunken und bewaffnet am Steuer gestoppt. Sydney/Rio de Janeiro – Gut zehn Wochen vor den Olympischen Spielen hat ein australischer Goldmedaillengewinner im Schießen nach einem F...   \n798  Neuschnee erzwang Absage, Kombination ersatzlos gestrichen. Crans Montana – Wegen zu viel Neuschnee ist die für den (heutigen) Samstag geplante Weltcup-Abfahrt der Damen in Crans Montana auf Sonnt...   \n801  Neuer Generalsekretär rechnet nicht mit Freispruch für Russin. Rom – Der designierte Generaldirektor der Welt-Antidoping-Agentur (WADA), Olivier Niggli, rechnet nicht mit einen Freispruch für die ...   \n\n                                                                                                                                                                                               Clean Article  \\\n705  Michael Diamond betrunken bewaffnet Steuer stoppen Sydney Rio de Janeiro gut zehn Woche olympisch Spiel australisch Goldmedaillengewinner Schieen Familienstreit Waffenlizenz verlieren Polizei stop...   \n798  Neuschnee Erzwang absagen Kombination ersatzlos streichen Crans Montana wegen Neuschnee Fuer heutig Samstag geplant weltcupabfahrt Dame Crans Montana Sonntag Uhr verschieben eigentlich Fuer Sonnta...   \n801  neu Generalsekretaer rechnen Freispruch Fuer russin rom designiert Generaldirektor weltantidopingagentur Wada Olivier Niggli rechnen Freispruch Fuer derzeit wegen Doping suspendiert Tennisspieleri...   \n\n    Predicted Name  Predicted Confidence  \n705       Panorama              0.839159  \n798       Panorama              0.500947  \n801       Panorama              0.352073  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target Name</th>\n      <th>Article</th>\n      <th>Clean Article</th>\n      <th>Predicted Name</th>\n      <th>Predicted Confidence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>705</th>\n      <td>Sport</td>\n      <td>Michael Diamond betrunken und bewaffnet am Steuer gestoppt. Sydney/Rio de Janeiro – Gut zehn Wochen vor den Olympischen Spielen hat ein australischer Goldmedaillengewinner im Schießen nach einem F...</td>\n      <td>Michael Diamond betrunken bewaffnet Steuer stoppen Sydney Rio de Janeiro gut zehn Woche olympisch Spiel australisch Goldmedaillengewinner Schieen Familienstreit Waffenlizenz verlieren Polizei stop...</td>\n      <td>Panorama</td>\n      <td>0.839159</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>Sport</td>\n      <td>Neuschnee erzwang Absage, Kombination ersatzlos gestrichen. Crans Montana – Wegen zu viel Neuschnee ist die für den (heutigen) Samstag geplante Weltcup-Abfahrt der Damen in Crans Montana auf Sonnt...</td>\n      <td>Neuschnee Erzwang absagen Kombination ersatzlos streichen Crans Montana wegen Neuschnee Fuer heutig Samstag geplant weltcupabfahrt Dame Crans Montana Sonntag Uhr verschieben eigentlich Fuer Sonnta...</td>\n      <td>Panorama</td>\n      <td>0.500947</td>\n    </tr>\n    <tr>\n      <th>801</th>\n      <td>Sport</td>\n      <td>Neuer Generalsekretär rechnet nicht mit Freispruch für Russin. Rom – Der designierte Generaldirektor der Welt-Antidoping-Agentur (WADA), Olivier Niggli, rechnet nicht mit einen Freispruch für die ...</td>\n      <td>neu Generalsekretaer rechnen Freispruch Fuer russin rom designiert Generaldirektor weltantidopingagentur Wada Olivier Niggli rechnen Freispruch Fuer derzeit wegen Doping suspendiert Tennisspieleri...</td>\n      <td>Panorama</td>\n      <td>0.352073</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weitere Falschsortierungen (andere Gruppe)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "res_df = (test_df[(test_df['Target Name'] == 'Sport') & (test_df['Predicted Name'] == 'Panorama')]\n",
    "       .sort_values(by=['Predicted Confidence'], ascending=False).head(5))\n",
    "res_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
